---
title: CUDAç¼–ç¨‹å…¥é—¨æŒ‡å—
date: 2026-02-07 18:30:00
tags: [CUDA, GPUç¼–ç¨‹, å¹¶è¡Œè®¡ç®—, NVIDIA]
categories: CUDAç¼–ç¨‹
---

# CUDAç¼–ç¨‹å…¥é—¨æŒ‡å—

CUDA (Compute Unified Device Architecture) æ˜¯ NVIDIA æ¨å‡ºçš„å¹¶è¡Œè®¡ç®—å¹³å°å’Œç¼–ç¨‹æ¨¡å‹ï¼Œå®ƒå…è®¸å¼€å‘è€…åˆ©ç”¨ GPU çš„å¼ºå¤§å¹¶è¡Œè®¡ç®—èƒ½åŠ›æ¥åŠ é€Ÿå„ç§åº”ç”¨ç¨‹åºã€‚

<!-- more -->

## ä»€ä¹ˆæ˜¯ CUDAï¼Ÿ

CUDA æ˜¯ä¸€ç§é€šç”¨å¹¶è¡Œè®¡ç®—æ¶æ„ï¼Œå®ƒä½¿å¾— GPU èƒ½å¤Ÿè§£å†³å¤æ‚çš„è®¡ç®—é—®é¢˜ã€‚é€šè¿‡ CUDAï¼Œå¼€å‘è€…å¯ä»¥ï¼š

- åˆ©ç”¨ GPU çš„æ•°åƒä¸ªæ ¸å¿ƒè¿›è¡Œå¹¶è¡Œè®¡ç®—
- å¤§å¹…æå‡è®¡ç®—å¯†é›†å‹ä»»åŠ¡çš„æ€§èƒ½
- ä½¿ç”¨ C/C++ ç­‰ç†Ÿæ‚‰çš„ç¼–ç¨‹è¯­è¨€

## ç¯å¢ƒé…ç½®

### 1. ç¡¬ä»¶è¦æ±‚

- NVIDIA GPUï¼ˆæ”¯æŒ CUDA çš„æ˜¾å¡ï¼‰
- è¶³å¤Ÿçš„æ˜¾å­˜ï¼ˆå»ºè®®è‡³å°‘ 2GBï¼‰

### 2. è½¯ä»¶å®‰è£…

**å®‰è£… CUDA Toolkitï¼š**

```bash
# Ubuntu/Debian
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get install cuda-toolkit-12-3

# è®¾ç½®ç¯å¢ƒå˜é‡
export PATH=/usr/local/cuda-12.3/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:$LD_LIBRARY_PATH
```

**éªŒè¯å®‰è£…ï¼š**

```bash
nvcc --version
nvidia-smi
```

## ç¬¬ä¸€ä¸ª CUDA ç¨‹åº

### Hello World ç¤ºä¾‹

åˆ›å»ºæ–‡ä»¶ `hello_cuda.cu`ï¼š

```cpp
#include <stdio.h>
#include <cuda_runtime.h>

// CUDA æ ¸å‡½æ•°
__global__ void helloFromGPU() {
    printf("Hello World from GPU thread %d!\n", threadIdx.x);
}

int main() {
    printf("Hello World from CPU!\n");
    
    // å¯åŠ¨ 10 ä¸ªçº¿ç¨‹çš„æ ¸å‡½æ•°
    helloFromGPU<<<1, 10>>>();
    
    // ç­‰å¾… GPU å®Œæˆ
    cudaDeviceSynchronize();
    
    return 0;
}
```

**ç¼–è¯‘è¿è¡Œï¼š**

```bash
nvcc hello_cuda.cu -o hello_cuda
./hello_cuda
```

## CUDA ç¼–ç¨‹åŸºç¡€æ¦‚å¿µ

### 1. æ ¸å‡½æ•°ï¼ˆKernelï¼‰

æ ¸å‡½æ•°æ˜¯åœ¨ GPU ä¸Šæ‰§è¡Œçš„å‡½æ•°ï¼Œä½¿ç”¨ `__global__` å…³é”®å­—å£°æ˜ï¼š

```cpp
__global__ void myKernel(int *data) {
    int idx = threadIdx.x;
    data[idx] = data[idx] * 2;
}
```

### 2. çº¿ç¨‹å±‚æ¬¡ç»“æ„

CUDA ä½¿ç”¨ä¸‰å±‚çº¿ç¨‹ç»„ç»‡ç»“æ„ï¼š

- **Gridï¼ˆç½‘æ ¼ï¼‰**ï¼šæ‰€æœ‰çº¿ç¨‹çš„é›†åˆ
- **Blockï¼ˆçº¿ç¨‹å—ï¼‰**ï¼šçº¿ç¨‹çš„åˆ†ç»„
- **Threadï¼ˆçº¿ç¨‹ï¼‰**ï¼šæœ€å°æ‰§è¡Œå•å…ƒ

```cpp
// å¯åŠ¨æ ¸å‡½æ•°ï¼š2 ä¸ª Blockï¼Œæ¯ä¸ª Block æœ‰ 256 ä¸ªçº¿ç¨‹
myKernel<<<2, 256>>>(data);
```

### 3. å†…å­˜ç®¡ç†

CUDA æä¾›äº†æ˜¾å¼çš„å†…å­˜ç®¡ç†å‡½æ•°ï¼š

```cpp
// åˆ†é…è®¾å¤‡å†…å­˜
int *d_data;
cudaMalloc(&d_data, size * sizeof(int));

// æ•°æ®ä¼ è¾“ï¼šä¸»æœº -> è®¾å¤‡
cudaMemcpy(d_data, h_data, size * sizeof(int), cudaMemcpyHostToDevice);

// æ•°æ®ä¼ è¾“ï¼šè®¾å¤‡ -> ä¸»æœº
cudaMemcpy(h_data, d_data, size * sizeof(int), cudaMemcpyDeviceToHost);

// é‡Šæ”¾è®¾å¤‡å†…å­˜
cudaFree(d_data);
```

## å‘é‡åŠ æ³•ç¤ºä¾‹

å®Œæ•´çš„å‘é‡åŠ æ³•ç¨‹åºï¼š

```cpp
#include <stdio.h>
#include <cuda_runtime.h>

#define N 1000000

// æ ¸å‡½æ•°ï¼šå‘é‡åŠ æ³•
__global__ void vectorAdd(float *a, float *b, float *c, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

int main() {
    float *h_a, *h_b, *h_c;
    float *d_a, *d_b, *d_c;
    size_t bytes = N * sizeof(float);
    
    // åˆ†é…ä¸»æœºå†…å­˜
    h_a = (float*)malloc(bytes);
    h_b = (float*)malloc(bytes);
    h_c = (float*)malloc(bytes);
    
    // åˆå§‹åŒ–æ•°æ®
    for (int i = 0; i < N; i++) {
        h_a[i] = i;
        h_b[i] = i * 2;
    }
    
    // åˆ†é…è®¾å¤‡å†…å­˜
    cudaMalloc(&d_a, bytes);
    cudaMalloc(&d_b, bytes);
    cudaMalloc(&d_c, bytes);
    
    // æ•°æ®ä¼ è¾“ï¼šä¸»æœº -> è®¾å¤‡
    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);
    
    // å¯åŠ¨æ ¸å‡½æ•°
    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, N);
    
    // æ•°æ®ä¼ è¾“ï¼šè®¾å¤‡ -> ä¸»æœº
    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);
    
    // éªŒè¯ç»“æœ
    for (int i = 0; i < 10; i++) {
        printf("c[%d] = %.2f\n", i, h_c[i]);
    }
    
    // é‡Šæ”¾å†…å­˜
    free(h_a); free(h_b); free(h_c);
    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);
    
    return 0;
}
```

## æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. åˆç†é€‰æ‹©çº¿ç¨‹å—å¤§å°

```cpp
// æ¨èï¼š256 æˆ– 512
int threadsPerBlock = 256;
```

### 2. ä½¿ç”¨å…±äº«å†…å­˜

```cpp
__global__ void useSharedMemory() {
    __shared__ float shared_data[256];
    shared_data[threadIdx.x] = /* æŸä¸ªå€¼ */;
    __syncthreads();  // åŒæ­¥æ‰€æœ‰çº¿ç¨‹
}
```

### 3. å†…å­˜åˆå¹¶è®¿é—®

ç¡®ä¿ç›¸é‚»çº¿ç¨‹è®¿é—®ç›¸é‚»å†…å­˜åœ°å€ï¼Œä»¥æé«˜å¸¦å®½åˆ©ç”¨ç‡ã€‚

### 4. é¿å…åˆ†æ”¯å‘æ•£

å°½é‡å‡å°‘çº¿ç¨‹æŸï¼ˆwarpï¼‰å†…çš„æ¡ä»¶åˆ†æ”¯ã€‚

## å¸¸ç”¨åº“æ¨è

- **cuBLAS**ï¼šçº¿æ€§ä»£æ•°è¿ç®—
- **cuFFT**ï¼šå¿«é€Ÿå‚…é‡Œå¶å˜æ¢
- **cuDNN**ï¼šæ·±åº¦å­¦ä¹ åŠ é€Ÿ
- **Thrust**ï¼šC++ æ¨¡æ¿åº“ï¼Œç±»ä¼¼ STL

## è°ƒè¯•å·¥å…·

- **cuda-gdb**ï¼šCUDA è°ƒè¯•å™¨
- **nvidia-smi**ï¼šGPU ç›‘æ§å·¥å…·
- **nvprof / nsys**ï¼šæ€§èƒ½åˆ†æå·¥å…·

```bash
# ç›‘æ§ GPU ä½¿ç”¨æƒ…å†µ
nvidia-smi -l 1

# æ€§èƒ½åˆ†æ
nvprof ./your_cuda_app
```

## å­¦ä¹ èµ„æº

1. **å®˜æ–¹æ–‡æ¡£**ï¼š[NVIDIA CUDA Documentation](https://docs.nvidia.com/cuda/)
2. **åœ¨çº¿è¯¾ç¨‹**ï¼šCourseraã€Udacity ä¸Šçš„ GPU ç¼–ç¨‹è¯¾ç¨‹
3. **å¼€æºé¡¹ç›®**ï¼šGitHub ä¸Šçš„ CUDA ç¤ºä¾‹ä»£ç 
4. **ä¹¦ç±æ¨è**ï¼šã€ŠCUDA by Exampleã€‹ã€ã€ŠProfessional CUDA C Programmingã€‹

## æ€»ç»“

CUDA ç¼–ç¨‹ä¸ºå¼€å‘è€…æä¾›äº†å¼ºå¤§çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼Œé€šè¿‡æœ¬æ–‡çš„ä»‹ç»ï¼Œæ‚¨åº”è¯¥å·²ç»æŒæ¡äº†ï¼š

- CUDA çš„åŸºæœ¬æ¦‚å¿µå’Œæ¶æ„
- å¦‚ä½•ç¼–å†™å’Œç¼–è¯‘ CUDA ç¨‹åº
- å†…å­˜ç®¡ç†å’Œæ•°æ®ä¼ è¾“
- çº¿ç¨‹ç»„ç»‡å’Œæ ¸å‡½æ•°è°ƒç”¨
- åŸºæœ¬çš„æ€§èƒ½ä¼˜åŒ–æŠ€å·§

éšç€å®è·µçš„æ·±å…¥ï¼Œæ‚¨å°†èƒ½å¤Ÿåˆ©ç”¨ GPU åŠ é€Ÿæ›´å¤æ‚çš„åº”ç”¨ï¼Œå¦‚ç§‘å­¦è®¡ç®—ã€æ·±åº¦å­¦ä¹ ã€å›¾åƒå¤„ç†ç­‰é¢†åŸŸã€‚

**å¼€å§‹æ‚¨çš„ CUDA ä¹‹æ—…å§ï¼** ğŸš€

---

*æœ¬æ–‡æœ€åæ›´æ–°æ—¶é—´ï¼š2026-02-07*